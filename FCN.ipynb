{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrU8eky/fLI8j+yalJ1WX4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NINE9-9-9/Flood-Detection/blob/main/FCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d29QxE-wq7uf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models.segmentation as segmentation\n",
        "import pytorch_lightning as pl\n",
        "!pip install segmentation-models-pytorch==0.1.0\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "\n",
        "class FCN(pl.LightningModule):\n",
        "    def __init__(self, num_classes=3, learning_rate=1e-4):\n",
        "        super(FCN, self).__init__()\n",
        "\n",
        "        self.weight = torch.Tensor([1.93445299, 36.60054169, 2.19400729])\n",
        "\n",
        "        self.model = segmentation.fcn_resnet101(pretrained=True)\n",
        "\n",
        "        # 修改第一层卷积层，使其接受13个通道作为输入\n",
        "        self.model.backbone.conv1 = nn.Conv2d(13, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "        self.model.classifier[4] = nn.Conv2d(512, num_classes, kernel_size=(1, 1), stride=(1, 1))\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        return self.model(x)['out']\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # 训练循环\n",
        "        images = batch[\"image\"].cuda()\n",
        "        labels = batch[\"mask\"].squeeze(1).cuda()\n",
        "        outputs = self(images).cuda()\n",
        "        loss = self.cross_entropy_loss_mask_invalid(outputs, labels, weight=self.weight)\n",
        "        # loss = self.calc_loss_mask_invalid(outputs, labels, weight=self.weight)\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        # 训练循环\n",
        "        images = batch[\"image\"].cuda()\n",
        "        labels = batch[\"mask\"].squeeze(1).cuda()\n",
        "        outputs = self(images).cuda()\n",
        "        loss = self.cross_entropy_loss_mask_invalid(outputs, labels, weight=self.weight)\n",
        "        # loss = self.calc_loss_mask_invalid(outputs, labels, weight=self.weight)\n",
        "        self.log('val_loss', loss)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # 定义优化器\n",
        "        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        return optimizer\n",
        "\n",
        "    def cross_entropy_loss_mask_invalid(self, logits: torch.Tensor, target:torch.Tensor, weight=None) -> float:\n",
        "\n",
        "      assert logits.dim() == 4, \"Expected logits to have 4 dimensions, but got {} dimensions.\".format(logits.dim())\n",
        "      assert target.dim() == 3, \"Expected target to have 3 dimensions, but got {} dimensions.\".format(target.dim())\n",
        "\n",
        "      valid = (target != 0)\n",
        "      target_without_invalids = (target - 1) * valid\n",
        "\n",
        "      weight = weight.cuda()\n",
        "      logits = logits.cuda()\n",
        "      target_without_invalids = target_without_invalids.cuda()\n",
        "    # BCE Loss (ignoring invalid values)\n",
        "      criterion = nn.CrossEntropyLoss(weight=weight.cuda(), reduction='none')  # (B, 1, H, W)\n",
        "\n",
        "      bce = criterion(logits, target_without_invalids)\n",
        "\n",
        "      bce *= valid  # mask out invalid pixels\n",
        "\n",
        "      return torch.sum(bce / (torch.sum(valid) + 1e-6))\n",
        "\n",
        "    def dice_loss_mask_invalid(self, logits, target, smooth=1.) -> float:\n",
        "\n",
        "      assert logits.dim() == 4, f\n",
        "      assert target.dim() == 3, f\n",
        "\n",
        "      pred = torch.softmax(logits, dim=1)\n",
        "      valid = (target != 0) # (B, H, W) tensor\n",
        "      target_without_invalids = (target - 1) * valid  # Set invalids to land\n",
        "\n",
        "      # target_without_invalids.cuda()\n",
        "      target_one_hot_without_invalid = torch.nn.functional.one_hot(target_without_invalids,\n",
        "                                                                 num_classes=pred.shape[1]).permute(0, 3, 1, 2)\n",
        "      axis_red = (2, 3) # H, W reduction\n",
        "\n",
        "      pred_valid = pred * valid.unsqueeze(1).float()  # # Set invalids to 0 (all values in prob tensor are 0\n",
        "\n",
        "      intersection = (pred_valid * target_one_hot_without_invalid).sum(dim=axis_red) # (B, C) tensor\n",
        "\n",
        "      union = pred_valid.sum(dim=axis_red) + target_one_hot_without_invalid.sum(dim=axis_red)  # (B, C) tensor\n",
        "\n",
        "      dice_score = ((2. * intersection + smooth) /\n",
        "                  (union + smooth))\n",
        "\n",
        "      loss = (1 - dice_score)  # (B, C) tensor\n",
        "\n",
        "      return torch.mean(loss)\n",
        "\n",
        "    def calc_loss_mask_invalid(self, logits, target,bce_weight=0.5, weight=None):\n",
        "\n",
        "      bce = self.cross_entropy_loss_mask_invalid(logits, target, weight=weight)\n",
        "\n",
        "      dice = self.dice_loss_mask_invalid(logits, target) # (B, C)\n",
        "\n",
        "      return bce * bce_weight + dice * (1 - bce_weight)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FCN2(pl.LightningModule):\n",
        "    def __init__(self, num_classes=3, learning_rate=1e-4):\n",
        "        super(FCN2, self).__init__()\n",
        "\n",
        "        self.weight = torch.Tensor([1.93445299, 36.60054169, 2.19400729])\n",
        "\n",
        "        self.model = segmentation.fcn_resnet50(pretrained=True)\n",
        "\n",
        "        # 修改第一层卷积层，使其接受13个通道作为输入\n",
        "        self.model.backbone.conv1 = nn.Conv2d(13, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "        self.model.classifier[4] = nn.Conv2d(512, num_classes, kernel_size=(1, 1), stride=(1, 1))\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        return self.model(x)['out']\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # 训练循环\n",
        "        images = batch[\"image\"].cuda()\n",
        "        labels = batch[\"mask\"].squeeze(1).cuda()\n",
        "        outputs = self(images).cuda()\n",
        "        loss = self.cross_entropy_loss_mask_invalid(outputs, labels, weight=self.weight)\n",
        "        # loss = self.calc_loss_mask_invalid(outputs, labels, weight=self.weight)\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        # 训练循环\n",
        "        images = batch[\"image\"].cuda()\n",
        "        labels = batch[\"mask\"].squeeze(1).cuda()\n",
        "        outputs = self(images).cuda()\n",
        "        # loss = self.cross_entropy_loss_mask_invalid(outputs, labels, weight=self.weight)\n",
        "        loss = self.calc_loss_mask_invalid(outputs, labels, weight=self.weight)\n",
        "        self.log('val_loss', loss)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # 定义优化器\n",
        "        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        return optimizer\n",
        "\n",
        "    def cross_entropy_loss_mask_invalid(self, logits: torch.Tensor, target:torch.Tensor, weight=None) -> float:\n",
        "\n",
        "      assert logits.dim() == 4, \"Expected logits to have 4 dimensions, but got {} dimensions.\".format(logits.dim())\n",
        "      assert target.dim() == 3, \"Expected target to have 3 dimensions, but got {} dimensions.\".format(target.dim())\n",
        "\n",
        "      valid = (target != 0)\n",
        "      target_without_invalids = (target - 1) * valid\n",
        "\n",
        "      weight = weight.cuda()\n",
        "      logits = logits.cuda()\n",
        "      target_without_invalids = target_without_invalids.cuda()\n",
        "    # BCE Loss (ignoring invalid values)\n",
        "      criterion = nn.CrossEntropyLoss(weight=weight.cuda(), reduction='none')  # (B, 1, H, W)\n",
        "\n",
        "      bce = criterion(logits, target_without_invalids)\n",
        "\n",
        "      bce *= valid  # mask out invalid pixels\n",
        "\n",
        "      return torch.sum(bce / (torch.sum(valid) + 1e-6))\n",
        "\n",
        "    def dice_loss_mask_invalid(self, logits, target, smooth=1.) -> float:\n",
        "\n",
        "      assert logits.dim() == 4, f\n",
        "      assert target.dim() == 3, f\n",
        "\n",
        "      pred = torch.softmax(logits, dim=1)\n",
        "      valid = (target != 0) # (B, H, W) tensor\n",
        "      target_without_invalids = (target - 1) * valid  # Set invalids to land\n",
        "\n",
        "      # target_without_invalids.cuda()\n",
        "      target_one_hot_without_invalid = torch.nn.functional.one_hot(target_without_invalids,\n",
        "                                                                 num_classes=pred.shape[1]).permute(0, 3, 1, 2)\n",
        "      axis_red = (2, 3) # H, W reduction\n",
        "\n",
        "      pred_valid = pred * valid.unsqueeze(1).float()  # # Set invalids to 0 (all values in prob tensor are 0\n",
        "\n",
        "      intersection = (pred_valid * target_one_hot_without_invalid).sum(dim=axis_red) # (B, C) tensor\n",
        "\n",
        "      union = pred_valid.sum(dim=axis_red) + target_one_hot_without_invalid.sum(dim=axis_red)  # (B, C) tensor\n",
        "\n",
        "      dice_score = ((2. * intersection + smooth) /\n",
        "                  (union + smooth))\n",
        "\n",
        "      loss = (1 - dice_score)  # (B, C) tensor\n",
        "\n",
        "      return torch.mean(loss)\n",
        "\n",
        "    def calc_loss_mask_invalid(self, logits, target,bce_weight=0.5, weight=None):\n",
        "\n",
        "      bce = self.cross_entropy_loss_mask_invalid(logits, target, weight=weight)\n",
        "\n",
        "      dice = self.dice_loss_mask_invalid(logits, target) # (B, C)\n",
        "\n",
        "      return bce * bce_weight + dice * (1 - bce_weight)"
      ],
      "metadata": {
        "id": "TPZRSYptIHeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "from torch.optim import Adam\n",
        "\n",
        "class DeepLabV3(pl.LightningModule):\n",
        "    def __init__(self, learning_rate=1e-4):\n",
        "        super(DeepLabV3, self).__init__()\n",
        "\n",
        "        self.weight = torch.Tensor([1.93445299, 36.60054169, 2.19400729])\n",
        "\n",
        "\n",
        "        # 获取预训练的 deeplabv3_resnet101 模型\n",
        "        self.deeplab = models.segmentation.deeplabv3_resnet101(pretrained=True)\n",
        "\n",
        "        # 修改第一层以接受 13 个通道的输入\n",
        "        self.deeplab.backbone.conv1 = nn.Conv2d(13, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "\n",
        "        # 修改分类器的最后一层以适应你的类别数量\n",
        "        self.deeplab.classifier[4] = nn.Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.deeplab(x)['out']\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch[\"image\"].cuda(), batch[\"mask\"].squeeze(1).cuda()\n",
        "        y_hat = self(x)\n",
        "        # loss = self.cross_entropy_loss_mask_invalid(y_hat, y, weight=self.weight)\n",
        "        loss = self.calc_loss_mask_invalid(y_hat, y, weight=self.weight)\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "\n",
        "        x, y = batch[\"image\"].cuda(), batch[\"mask\"].squeeze(1).cuda()\n",
        "        y_hat = self(x)\n",
        "\n",
        "        # loss = self.cross_entropy_loss_mask_invalid(y_hat, y, weight=self.weight)\n",
        "        loss = self.calc_loss_mask_invalid(y_hat, y, weight=self.weight)\n",
        "        self.log('val_loss', loss)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return Adam(self.parameters(), lr=self.learning_rate)\n",
        "\n",
        "    def cross_entropy_loss_mask_invalid(self, logits: torch.Tensor, target:torch.Tensor, weight=None) -> float:\n",
        "\n",
        "      assert logits.dim() == 4, \"Expected logits to have 4 dimensions, but got {} dimensions.\".format(logits.dim())\n",
        "      assert target.dim() == 3, \"Expected target to have 3 dimensions, but got {} dimensions.\".format(target.dim())\n",
        "\n",
        "      valid = (target != 0)\n",
        "      target_without_invalids = (target - 1) * valid\n",
        "\n",
        "      weight = weight.cuda()\n",
        "      logits = logits.cuda()\n",
        "      target_without_invalids = target_without_invalids.cuda()\n",
        "    # BCE Loss (ignoring invalid values)\n",
        "      criterion = nn.CrossEntropyLoss(weight=weight.cuda(), reduction='none')  # (B, 1, H, W)\n",
        "\n",
        "      bce = criterion(logits, target_without_invalids)\n",
        "\n",
        "      bce *= valid  # mask out invalid pixels\n",
        "\n",
        "      return torch.sum(bce / (torch.sum(valid) + 1e-6))\n",
        "\n",
        "    def dice_loss_mask_invalid(self, logits, target, smooth=1.) -> float:\n",
        "\n",
        "      assert logits.dim() == 4, f\n",
        "      assert target.dim() == 3, f\n",
        "\n",
        "      pred = torch.softmax(logits, dim=1)\n",
        "      valid = (target != 0) # (B, H, W) tensor\n",
        "      target_without_invalids = (target - 1) * valid  # Set invalids to land\n",
        "\n",
        "      # target_without_invalids.cuda()\n",
        "      target_one_hot_without_invalid = torch.nn.functional.one_hot(target_without_invalids,\n",
        "                                                                 num_classes=pred.shape[1]).permute(0, 3, 1, 2)\n",
        "      axis_red = (2, 3) # H, W reduction\n",
        "\n",
        "      pred_valid = pred * valid.unsqueeze(1).float()  # # Set invalids to 0 (all values in prob tensor are 0\n",
        "\n",
        "      intersection = (pred_valid * target_one_hot_without_invalid).sum(dim=axis_red) # (B, C) tensor\n",
        "\n",
        "      union = pred_valid.sum(dim=axis_red) + target_one_hot_without_invalid.sum(dim=axis_red)  # (B, C) tensor\n",
        "\n",
        "      dice_score = ((2. * intersection + smooth) /\n",
        "                  (union + smooth))\n",
        "\n",
        "      loss = (1 - dice_score)  # (B, C) tensor\n",
        "\n",
        "      return torch.mean(loss)\n",
        "\n",
        "    def calc_loss_mask_invalid(self, logits, target,bce_weight=0.5, weight=None):\n",
        "\n",
        "      bce = self.cross_entropy_loss_mask_invalid(logits, target, weight=weight)\n",
        "\n",
        "      dice = self.dice_loss_mask_invalid(logits, target) # (B, C)\n",
        "\n",
        "      return bce * bce_weight + dice * (1 - bce_weight)"
      ],
      "metadata": {
        "id": "BrGXN7U3ET3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "class PSPModule(nn.Module):\n",
        "    def __init__(self, in_channels, bin_sizes):\n",
        "        super(PSPModule, self).__init__()\n",
        "        self.stages = nn.ModuleList([self._make_stage(in_channels, size) for size in bin_sizes])\n",
        "        self.bottleneck = nn.Conv2d(in_channels * (len(bin_sizes) + 1), in_channels, kernel_size=1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def _make_stage(self, in_channels, size):\n",
        "        prior = nn.AdaptiveAvgPool2d(output_size=(size, size))\n",
        "        conv = nn.Conv2d(in_channels, in_channels, kernel_size=1, bias=False)\n",
        "        return nn.Sequential(prior, conv)\n",
        "\n",
        "    def forward(self, feats):\n",
        "        h, w = feats.size(2), feats.size(3)\n",
        "        pyramids = [feats]\n",
        "        pyramids.extend([nn.functional.interpolate(stage(feats), size=(h, w), mode='bilinear', align_corners=True) for stage in self.stages])\n",
        "        output = torch.cat(pyramids, dim=1)\n",
        "        return self.relu(self.bottleneck(output))\n",
        "\n",
        "class PSPNet(pl.LightningModule):\n",
        "    def __init__(self, in_channels=13, num_classes=3, bin_sizes=[1, 2, 3, 6]):\n",
        "        super(PSPNet, self).__init__()\n",
        "\n",
        "        self.weight = torch.Tensor([1.93445299, 36.60054169, 2.19400729])\n",
        "        resnet = models.resnet101(pretrained=True)\n",
        "        resnet.conv1 = nn.Conv2d(in_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-2])\n",
        "        self.psp = PSPModule(2048, [1, 2, 4, 8, 16])\n",
        "        self.up_sampling = nn.Sequential(\n",
        "            nn.Conv2d(2048, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "\n",
        "            nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "\n",
        "            # nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1),\n",
        "            # nn.BatchNorm2d(256),\n",
        "            # nn.ReLU(inplace=True),\n",
        "            # nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "\n",
        "            # nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            # nn.BatchNorm2d(256),\n",
        "            # nn.ReLU(inplace=True),\n",
        "            # nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        )\n",
        "        self.classifier = nn.Conv2d(256, num_classes, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.psp(x)\n",
        "        x = self.up_sampling(x)\n",
        "        x = self.classifier(x)\n",
        "        return F.interpolate(x, size=(x.size(2)*8, x.size(3)*8), mode='bilinear', align_corners=True)\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch[\"image\"].cuda(), batch[\"mask\"].squeeze(1).cuda()\n",
        "        y_hat = self(x)\n",
        "        loss = self.cross_entropy_loss_mask_invalid(y_hat, y, weight=self.weight)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "\n",
        "        x, y = batch[\"image\"].cuda(), batch[\"mask\"].squeeze(1).cuda()\n",
        "        y_hat = self(x)\n",
        "\n",
        "        loss = self.cross_entropy_loss_mask_invalid(y_hat, y, weight=self.weight)\n",
        "\n",
        "        self.log('val_loss', loss)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "    def cross_entropy_loss_mask_invalid(self, logits: torch.Tensor, target:torch.Tensor, weight=None) -> float:\n",
        "\n",
        "      assert logits.dim() == 4, \"Expected logits to have 4 dimensions, but got {} dimensions.\".format(logits.dim())\n",
        "      assert target.dim() == 3, \"Expected target to have 3 dimensions, but got {} dimensions.\".format(target.dim())\n",
        "\n",
        "      valid = (target != 0)\n",
        "      target_without_invalids = (target - 1) * valid\n",
        "\n",
        "      weight = weight.cuda()\n",
        "      logits = logits.cuda()\n",
        "      target_without_invalids = target_without_invalids.cuda()\n",
        "    # BCE Loss (ignoring invalid values)\n",
        "      criterion = nn.CrossEntropyLoss(weight=weight.cuda(), reduction='none')  # (B, 1, H, W)\n",
        "\n",
        "      bce = criterion(logits, target_without_invalids)\n",
        "\n",
        "      bce *= valid  # mask out invalid pixels\n",
        "\n",
        "      return torch.sum(bce / (torch.sum(valid) + 1e-6))"
      ],
      "metadata": {
        "id": "idXL0t5tFUbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SegNet(pl.LightningModule):\n",
        "    def __init__(self, num_classes=3):\n",
        "        super(SegNet, self).__init__()\n",
        "        self.weight = torch.Tensor([1.93445299, 36.60054169, 2.19400729])\n",
        "        # 使用预训练的 VGG16 模型\n",
        "        vgg16 = models.vgg16_bn(pretrained=True)\n",
        "\n",
        "        # 修改VGG的第一个卷积层以接受13个输入通道\n",
        "        vgg16.features[0] = nn.Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "        inplace = True\n",
        "        batchNorm_momentum = 0.1\n",
        "        vgg16_bn = list(vgg16.features.children())\n",
        "        self.encoder1 = nn.Sequential(*vgg16_bn[0:6])\n",
        "        self.encoder2 = nn.Sequential(*vgg16_bn[7:13])\n",
        "        self.encoder3 = nn.Sequential(*vgg16_bn[14:23])\n",
        "        self.encoder4 = nn.Sequential(*vgg16_bn[24:33])\n",
        "        self.encoder5 = nn.Sequential(*vgg16_bn[34:-1])\n",
        "        self.decoder5 = nn.Sequential(\n",
        "                     nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "                     nn.BatchNorm2d(512, momentum=batchNorm_momentum),\n",
        "                     nn.ReLU(inplace),\n",
        "                     nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "                     nn.BatchNorm2d(512, momentum=batchNorm_momentum),\n",
        "                     nn.ReLU(inplace),\n",
        "                     nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "                     nn.BatchNorm2d(512, momentum=batchNorm_momentum),\n",
        "                     nn.ReLU(inplace),\n",
        "                     )\n",
        "        self.decoder4 = nn.Sequential(\n",
        "                     nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "                     nn.BatchNorm2d(512, momentum=batchNorm_momentum),\n",
        "                     nn.ReLU(inplace),\n",
        "                     nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "                     nn.BatchNorm2d(512, momentum=batchNorm_momentum),\n",
        "                     nn.ReLU(inplace),\n",
        "                     nn.Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "                     nn.BatchNorm2d(256, momentum=batchNorm_momentum),\n",
        "                     nn.ReLU(inplace),\n",
        "                     )\n",
        "        self.decoder3 = nn.Sequential(\n",
        "                      nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "                      nn.BatchNorm2d(256, momentum=batchNorm_momentum),\n",
        "                      nn.ReLU(inplace),\n",
        "                      nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "                      nn.BatchNorm2d(256, momentum=batchNorm_momentum),\n",
        "                      nn.ReLU(inplace),\n",
        "                      nn.Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "                      nn.BatchNorm2d(128, momentum=batchNorm_momentum),\n",
        "                      nn.ReLU(inplace),\n",
        "                      )\n",
        "        self.decoder2 = nn.Sequential(\n",
        "                      nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "                      nn.BatchNorm2d(128, momentum=batchNorm_momentum),\n",
        "                      nn.ReLU(inplace),\n",
        "                      nn.Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "                      nn.BatchNorm2d(64, momentum=batchNorm_momentum),\n",
        "                      nn.ReLU(inplace),\n",
        "                      )\n",
        "        self.decoder1 = nn.Sequential(\n",
        "                      nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "                      nn.BatchNorm2d(64, momentum=batchNorm_momentum),\n",
        "                      nn.ReLU(inplace),\n",
        "                      nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "                      nn.BatchNorm2d(64, momentum=batchNorm_momentum),\n",
        "                      nn.ReLU(inplace),\n",
        "                      nn.Conv2d(64, num_classes, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "                      )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder1(x)\n",
        "        size1 = x.size()\n",
        "        x, idx1 = F.max_pool2d(x, kernel_size=(2, 2), stride=(2, 2), return_indices=True)\n",
        "        x = self.encoder2(x)\n",
        "        size2 = x.size()\n",
        "        x, idx2 = F.max_pool2d(x, kernel_size=(2, 2), stride=(2, 2), return_indices=True)\n",
        "        x = self.encoder3(x)\n",
        "        size3 = x.size()\n",
        "        x, idx3 = F.max_pool2d(x, kernel_size=(2, 2), stride=(2, 2), return_indices=True)\n",
        "\n",
        "        x = self.encoder4(x)\n",
        "        size4 = x.size()\n",
        "        x, idx4 = F.max_pool2d(x, kernel_size=(2, 2), stride=(2, 2), return_indices=True)\n",
        "        x = self.encoder5(x)\n",
        "        size5 = x.size()\n",
        "        x, idx5 = F.max_pool2d(x, kernel_size=(2, 2), stride=(2, 2), return_indices=True)\n",
        "        x = self.decoder5(F.max_unpool2d(x, idx5, kernel_size=(2, 2), stride=(2, 2), output_size = size5))\n",
        "        x = self.decoder4(F.max_unpool2d(x, idx4, kernel_size=(2, 2), stride=(2, 2), output_size = size4))\n",
        "\n",
        "        x = self.decoder3(F.max_unpool2d(x, idx3, kernel_size=(2, 2), stride=(2, 2), output_size = size3))\n",
        "        x = self.decoder2(F.max_unpool2d(x, idx2, kernel_size=(2, 2), stride=(2, 2), output_size = size2))\n",
        "        x = self.decoder1(F.max_unpool2d(x, idx1, kernel_size=(2, 2), stride=(2, 2), output_size = size1))\n",
        "        x = F.softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch[\"image\"].cuda(), batch[\"mask\"].squeeze(1).cuda()\n",
        "        y_hat = self(x)\n",
        "        loss = self.cross_entropy_loss_mask_invalid(y_hat, y, weight=self.weight)\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "\n",
        "        x, y = batch[\"image\"].cuda(), batch[\"mask\"].squeeze(1).cuda()\n",
        "        y_hat = self(x)\n",
        "\n",
        "        loss = self.cross_entropy_loss_mask_invalid(y_hat, y, weight=self.weight)\n",
        "\n",
        "        self.log('val_loss', loss)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
        "\n",
        "    def cross_entropy_loss_mask_invalid(self, logits: torch.Tensor, target:torch.Tensor, weight=None) -> float:\n",
        "\n",
        "      assert logits.dim() == 4, \"Expected logits to have 4 dimensions, but got {} dimensions.\".format(logits.dim())\n",
        "      assert target.dim() == 3, \"Expected target to have 3 dimensions, but got {} dimensions.\".format(target.dim())\n",
        "\n",
        "      valid = (target != 0)\n",
        "      target_without_invalids = (target - 1) * valid\n",
        "\n",
        "      weight = weight.cuda()\n",
        "      logits = logits.cuda()\n",
        "      target_without_invalids = target_without_invalids.cuda()\n",
        "    # BCE Loss (ignoring invalid values)\n",
        "      criterion = nn.CrossEntropyLoss(weight=weight.cuda(), reduction='none')  # (B, 1, H, W)\n",
        "\n",
        "      bce = criterion(logits, target_without_invalids)\n",
        "\n",
        "      bce *= valid  # mask out invalid pixels\n",
        "\n",
        "      return torch.sum(bce / (torch.sum(valid) + 1e-6))"
      ],
      "metadata": {
        "id": "qhyWfP-8bw7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "from torch.nn import functional as F\n",
        "from torchvision.models import resnet18\n",
        "from torch.nn.modules.transformer import TransformerEncoder, TransformerEncoderLayer\n",
        "\n",
        "class SegFormer(pl.LightningModule):\n",
        "    def __init__(self, in_channels=13, num_classes=3):\n",
        "        super(SegFormer, self).__init__()\n",
        "\n",
        "        self.weight = torch.Tensor([1.93445299, 36.60054169, 2.19400729])\n",
        "\n",
        "        self.backbone = resnet18(pretrained=True)\n",
        "        self.backbone.conv1 = nn.Conv2d(in_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "\n",
        "        # Transformer 编码器\n",
        "        encoder_layers = TransformerEncoderLayer(d_model=512, nhead=8)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, num_layers=4)\n",
        "\n",
        "        batchNorm_momentum = 0.1\n",
        "        inplace = True\n",
        "        # 解码器部分\n",
        "        self.decoder1 = nn.Sequential(\n",
        "                     nn.ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)),\n",
        "                     nn.BatchNorm2d(512, momentum=batchNorm_momentum),\n",
        "                     nn.ReLU(inplace))\n",
        "        self.decoder2 = nn.Sequential(\n",
        "                     nn.ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)),\n",
        "                     nn.BatchNorm2d(256, momentum=batchNorm_momentum),\n",
        "                     nn.ReLU(inplace))\n",
        "        self.decoder3 = nn.Sequential(\n",
        "                     nn.ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)),\n",
        "                     nn.BatchNorm2d(128, momentum=batchNorm_momentum),\n",
        "                     nn.ReLU(inplace))\n",
        "        self.decoder4 = nn.Sequential(\n",
        "                     nn.ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)),\n",
        "                     nn.BatchNorm2d(64, momentum=batchNorm_momentum),\n",
        "                     nn.ReLU(inplace))\n",
        "        self.decoder5 = nn.Sequential(\n",
        "                     nn.ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)),\n",
        "                     nn.BatchNorm2d(32, momentum=batchNorm_momentum),\n",
        "                     nn.ReLU(inplace))  # 添加额外的反卷积层\n",
        "\n",
        "        # 分割头\n",
        "        self.segmentation_head = nn.Conv2d(32, num_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 通过 backbone\n",
        "        x1 = self.backbone.conv1(x)\n",
        "        x1 = self.backbone.bn1(x1)\n",
        "        x1 = self.backbone.relu(x1)\n",
        "        x2 = self.backbone.maxpool(x1)\n",
        "\n",
        "        x2 = self.backbone.layer1(x2)\n",
        "        x3 = self.backbone.layer2(x2)\n",
        "        x4 = self.backbone.layer3(x3)\n",
        "        x5 = self.backbone.layer4(x4)\n",
        "\n",
        "        # 调整形状以适应 Transformer\n",
        "        B, C, H, W = x5.shape\n",
        "        x5 = x5.permute(0, 2, 3, 1)  # [B, H, W, C]\n",
        "        x5 = x5.flatten(1, 2)  # [B, H*W, C]\n",
        "\n",
        "        # 通过 Transformer 编码器\n",
        "        x5 = self.transformer_encoder(x5)\n",
        "\n",
        "        # 调整形状回来\n",
        "        x5 = x5.view(B, H, W, C).permute(0, 3, 1, 2)  # [B, C, H, W]\n",
        "\n",
        "        # 通过解码器部分\n",
        "        x = self.decoder1(x5)\n",
        "        x = self.decoder2(x)\n",
        "        x = self.decoder3(x)\n",
        "        x = self.decoder4(x)\n",
        "        x = self.decoder5(x)  # 通过额外的反卷积层\n",
        "\n",
        "        # 通过分割头\n",
        "        x = self.segmentation_head(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch[\"image\"].cuda(), batch[\"mask\"].squeeze(1).cuda()\n",
        "        y_hat = self(x)\n",
        "        loss = self.cross_entropy_loss_mask_invalid(y_hat, y, weight=self.weight)\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "\n",
        "        x, y = batch[\"image\"].cuda(), batch[\"mask\"].squeeze(1).cuda()\n",
        "        y_hat = self(x)\n",
        "\n",
        "        loss = self.cross_entropy_loss_mask_invalid(y_hat, y, weight=self.weight)\n",
        "\n",
        "        self.log('val_loss', loss)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
        "\n",
        "    def cross_entropy_loss_mask_invalid(self, logits: torch.Tensor, target:torch.Tensor, weight=None) -> float:\n",
        "\n",
        "      assert logits.dim() == 4, \"Expected logits to have 4 dimensions, but got {} dimensions.\".format(logits.dim())\n",
        "      assert target.dim() == 3, \"Expected target to have 3 dimensions, but got {} dimensions.\".format(target.dim())\n",
        "\n",
        "      valid = (target != 0)\n",
        "      target_without_invalids = (target - 1) * valid\n",
        "\n",
        "      weight = weight.cuda()\n",
        "      logits = logits.cuda()\n",
        "      target_without_invalids = target_without_invalids.cuda()\n",
        "    # BCE Loss (ignoring invalid values)\n",
        "      criterion = nn.CrossEntropyLoss(weight=weight.cuda(), reduction='none')  # (B, 1, H, W)\n",
        "\n",
        "      bce = criterion(logits, target_without_invalids)\n",
        "\n",
        "      bce *= valid  # mask out invalid pixels\n",
        "\n",
        "      return torch.sum(bce / (torch.sum(valid) + 1e-6))"
      ],
      "metadata": {
        "id": "U5P7oqOWcFs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "import torchvision.models as models\n",
        "\n",
        "class UNet(pl.LightningModule):\n",
        "    def __init__(self, in_channels=13, num_classes=3):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        self.weight = torch.Tensor([1.93445299, 36.60054169, 2.19400729])\n",
        "\n",
        "        self.resnet101 = models.resnet101(pretrained=True)\n",
        "        self.resnet101.conv1 = nn.Conv2d(in_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "        # 编码器部分\n",
        "        self.enc1 = nn.Sequential(self.resnet101.conv1, self.resnet101.bn1, self.resnet101.relu, self.resnet101.maxpool) (64, 128, 128)\n",
        "        self.enc2 = self.resnet101.layer1 //(256, 64, 64)\n",
        "        self.enc3 = self.resnet101.layer2 //(512, 32, 32)\n",
        "        self.enc4 = self.resnet101.layer3 //(1024, 16, 16)\n",
        "        self.enc5 = self.resnet101.layer4 //(2048, 8, 8)\n",
        "\n",
        "        # 解码器部分\n",
        "        self.dec5 = self.conv_block(2048, 1024)\n",
        "        self.dec4 = self.conv_block(1024, 512)\n",
        "        self.dec3 = self.conv_block(512, 256)\n",
        "        self.dec2 = self.conv_block(256, 64)\n",
        "        self.dec1 = nn.Conv2d(64, num_classes, 1)\n",
        "\n",
        "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "    def conv_block(self, in_channels, out_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.enc1(x)\n",
        "        enc2 = self.enc2(enc1)\n",
        "        enc3 = self.enc3(enc2)\n",
        "        enc4 = self.enc4(enc3)\n",
        "        enc5 = self.enc5(enc4)\n",
        "\n",
        "        dec5 = self.up(self.dec5(enc5))\n",
        "        dec4 = self.up(self.dec4(dec5 + enc4))\n",
        "        dec3 = self.up(self.dec3(dec4 + enc3))\n",
        "        dec2 = self.up(self.dec2(dec3 + enc2))\n",
        "        dec1 = self.dec1(self.up(dec2))\n",
        "\n",
        "        return dec1\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch[\"image\"].cuda(), batch[\"mask\"].squeeze(1).cuda()\n",
        "        y_hat = self(x)\n",
        "        loss = self.cross_entropy_loss_mask_invalid(y_hat, y, weight=self.weight)\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "\n",
        "        x, y = batch[\"image\"].cuda(), batch[\"mask\"].squeeze(1).cuda()\n",
        "        y_hat = self(x)\n",
        "\n",
        "        loss = self.cross_entropy_loss_mask_invalid(y_hat, y, weight=self.weight)\n",
        "\n",
        "        self.log('val_loss', loss)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
        "\n",
        "    def cross_entropy_loss_mask_invalid(self, logits: torch.Tensor, target:torch.Tensor, weight=None) -> float:\n",
        "\n",
        "      assert logits.dim() == 4, \"Expected logits to have 4 dimensions, but got {} dimensions.\".format(logits.dim())\n",
        "      assert target.dim() == 3, \"Expected target to have 3 dimensions, but got {} dimensions.\".format(target.dim())\n",
        "\n",
        "      valid = (target != 0)\n",
        "      target_without_invalids = (target - 1) * valid\n",
        "\n",
        "      weight = weight.cuda()\n",
        "      logits = logits.cuda()\n",
        "      target_without_invalids = target_without_invalids.cuda()\n",
        "    # BCE Loss (ignoring invalid values)\n",
        "      criterion = nn.CrossEntropyLoss(weight=weight.cuda(), reduction='none')  # (B, 1, H, W)\n",
        "\n",
        "      bce = criterion(logits, target_without_invalids)\n",
        "\n",
        "      bce *= valid  # mask out invalid pixels\n",
        "\n",
        "      return torch.sum(bce / (torch.sum(valid) + 1e-6))"
      ],
      "metadata": {
        "id": "xsdWoAdpXfmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rrhZ6jQbIciL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "class AttentionBlock(nn.Module):\n",
        "    def __init__(self, F_g, F_l, F_int):\n",
        "        super(AttentionBlock, self).__init__()\n",
        "        self.W_g = nn.Sequential(\n",
        "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(F_int)\n",
        "        )\n",
        "\n",
        "        self.W_x = nn.Sequential(\n",
        "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(F_int)\n",
        "        )\n",
        "\n",
        "        self.psi = nn.Sequential(\n",
        "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, g, x):\n",
        "        g1 = self.W_g(g)\n",
        "        x1 = self.W_x(x)\n",
        "        psi = self.psi(g1 + x1)\n",
        "        return x * psi\n",
        "\n",
        "\n",
        "class ASPP(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, rates=[12, 24, 36]):\n",
        "        super(ASPP, self).__init__()\n",
        "        self.aspp_blocks = nn.ModuleList()\n",
        "\n",
        "        # 1x1 Convolution\n",
        "        self.aspp_blocks.append(nn.Conv2d(in_channels, out_channels, 1, bias=False))\n",
        "\n",
        "        # 3x3 Convolution with different dilation rates\n",
        "        for rate in rates:\n",
        "            self.aspp_blocks.append(nn.Conv2d(in_channels, out_channels, 3, padding=rate, dilation=rate, bias=False))\n",
        "\n",
        "        # Image-level features\n",
        "        self.global_avg_pool = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Conv2d(in_channels, out_channels, 1, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = [block(x) for block in self.aspp_blocks]\n",
        "        global_features = self.global_avg_pool(x)\n",
        "        global_features = nn.Upsample(size=x.size()[2:], mode='bilinear', align_corners=True)(global_features)\n",
        "        features.append(global_features)\n",
        "        return torch.cat(features, dim=1)\n",
        "\n",
        "\n",
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, channel, reduction=16):\n",
        "        super(SEBlock, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y.expand_as(x)\n",
        "\n",
        "\n",
        "class UNetPlus(pl.LightningModule):\n",
        "    def __init__(self, in_channels=13, num_classes=3):\n",
        "        super(UNetPlus, self).__init__()\n",
        "\n",
        "        self.weight = torch.Tensor([1.93445299, 36.60054169, 2.19400729])\n",
        "\n",
        "        self.resnet101 = models.resnet101(pretrained=True)\n",
        "        self.resnet101.conv1 = nn.Conv2d(in_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "        # 编码器部分\n",
        "        self.enc1 = nn.Sequential(self.resnet101.conv1, self.resnet101.bn1, self.resnet101.relu, self.resnet101.maxpool)\n",
        "        self.enc2 = self.resnet101.layer1\n",
        "        self.sbblock1 = SEBlock(256)\n",
        "        self.enc3 = self.resnet101.layer2\n",
        "        self.sbblock2 = SEBlock(512)\n",
        "        self.enc4 = self.resnet101.layer3\n",
        "        self.sbblock3 = SEBlock(1024)\n",
        "        self.enc5 = self.resnet101.layer4\n",
        "\n",
        "        self.aspp1 = ASPP(2048, 256)\n",
        "        self.project1 = nn.Sequential(nn.Conv2d(1280, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
        "                      nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Dropout(p=0.5, inplace=False))\n",
        "\n",
        "        self.attention1 = AttentionBlock(2048, 2048, 2048)\n",
        "        self.up1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.dec1 = self.conv_block(4096, 1024)\n",
        "        self.attention2 = AttentionBlock(1024, 1024, 1024)\n",
        "        self.up2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.dec2 = self.conv_block(2048, 512)\n",
        "        self.attention3 = AttentionBlock(512, 512, 512)\n",
        "        self.up3 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.dec3 = self.conv_block(1024, 256)\n",
        "        self.attention4 = AttentionBlock(256, 256, 256)\n",
        "        self.up4 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.dec4 = self.conv_block(512, 256)\n",
        "        self.up5 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "        self.aspp2 = ASPP(256, 32)\n",
        "        self.project2 = nn.Sequential(nn.Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
        "                      nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Dropout(p=0.5, inplace=False))\n",
        "\n",
        "        self.classfication = nn.Conv2d(128, num_classes, kernel_size=(1, 1), stride=(1, 1))\n",
        "\n",
        "\n",
        "    def conv_block(self, in_channels, out_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        enc1 = self.enc1(x)\n",
        "        enc2 = self.enc2(enc1)\n",
        "        # sbblock1 = self.sbblock1(enc2)\n",
        "        enc3 = self.enc3(enc2)\n",
        "        # sbblock2 = self.sbblock2(enc3)\n",
        "        enc4 = self.enc4(enc3)\n",
        "        # sbblock3 = self.sbblock3(enc4)\n",
        "        enc5 = self.enc5(enc4)\n",
        "\n",
        "        aspp1 = self.aspp1(enc5)\n",
        "        project1 = self.project1(aspp1)\n",
        "\n",
        "        # up1 = self.up(project1)\n",
        "        attention1 = self.attention1(enc5, project1)\n",
        "        dec1 = self.dec1(torch.cat((attention1, enc5), dim=1))\n",
        "\n",
        "        up2 = self.up1(dec1)\n",
        "        attention2 = self.attention2(enc4, up2)\n",
        "        dec2 = self.dec2(torch.cat((attention2, enc4), dim=1))\n",
        "\n",
        "        up3 = self.up2(dec2)\n",
        "        attention3 = self.attention3(enc3, up3)\n",
        "        dec3 = self.dec3(torch.cat((attention3, enc3), dim=1))\n",
        "\n",
        "\n",
        "        up4 = self.up3(dec3)\n",
        "        attention4 = self.attention4(enc2, up4)\n",
        "        dec4 = self.dec4(torch.cat((attention4, enc2), dim=1))\n",
        "\n",
        "        up5 = self.up4(dec4)\n",
        "        aspp2 = self.aspp2(up5)\n",
        "        up1 = self.up5(aspp2)\n",
        "        project2 = self.project2(up1)\n",
        "\n",
        "        classification = self.classfication(project2)\n",
        "\n",
        "        return classification\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch[\"image\"].cuda(), batch[\"mask\"].squeeze(1).cuda()\n",
        "        y_hat = self(x)\n",
        "        loss = self.cross_entropy_loss_mask_invalid(y_hat, y, weight=self.weight)\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "\n",
        "        x, y = batch[\"image\"].cuda(), batch[\"mask\"].squeeze(1).cuda()\n",
        "        y_hat = self(x)\n",
        "\n",
        "        loss = self.cross_entropy_loss_mask_invalid(y_hat, y, weight=self.weight)\n",
        "\n",
        "        self.log('val_loss', loss)\n",
        "\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
        "\n",
        "    def cross_entropy_loss_mask_invalid(self, logits: torch.Tensor, target:torch.Tensor, weight=None) -> float:\n",
        "\n",
        "      assert logits.dim() == 4, \"Expected logits to have 4 dimensions, but got {} dimensions.\".format(logits.dim())\n",
        "      assert target.dim() == 3, \"Expected target to have 3 dimensions, but got {} dimensions.\".format(target.dim())\n",
        "\n",
        "      valid = (target != 0)\n",
        "      target_without_invalids = (target - 1) * valid\n",
        "\n",
        "      weight = weight.cuda()\n",
        "      logits = logits.cuda()\n",
        "      target_without_invalids = target_without_invalids.cuda()\n",
        "    # BCE Loss (ignoring invalid values)\n",
        "      criterion = nn.CrossEntropyLoss(weight=weight.cuda(), reduction='none')  # (B, 1, H, W)\n",
        "\n",
        "      bce = criterion(logits, target_without_invalids)\n",
        "\n",
        "      bce *= valid  # mask out invalid pixels\n",
        "\n",
        "      return torch.sum(bce / (torch.sum(valid) + 1e-6))\n",
        "\n"
      ],
      "metadata": {
        "id": "I42wkD7RHdIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "class AttentionBlock(nn.Module):\n",
        "    def __init__(self, F_g, F_l, F_int):\n",
        "        super(AttentionBlock, self).__init__()\n",
        "        self.W_g = nn.Sequential(\n",
        "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(F_int)\n",
        "        )\n",
        "\n",
        "        self.W_x = nn.Sequential(\n",
        "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(F_int)\n",
        "        )\n",
        "\n",
        "        self.psi = nn.Sequential(\n",
        "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, g, x):\n",
        "        g1 = self.W_g(g)\n",
        "        x1 = self.W_x(x)\n",
        "        psi = self.psi(g1 + x1)\n",
        "        return x * psi\n",
        "\n",
        "\n",
        "class ASPP(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, rates=[12, 24, 36]):\n",
        "        super(ASPP, self).__init__()\n",
        "        self.aspp_blocks = nn.ModuleList()\n",
        "\n",
        "        # 1x1 Convolution\n",
        "        self.aspp_blocks.append(nn.Conv2d(in_channels, out_channels, 1, bias=False))\n",
        "\n",
        "        # 3x3 Convolution with different dilation rates\n",
        "        for rate in rates:\n",
        "            self.aspp_blocks.append(nn.Conv2d(in_channels, out_channels, 3, padding=rate, dilation=rate, bias=False))\n",
        "\n",
        "        # Image-level features\n",
        "        self.global_avg_pool = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Conv2d(in_channels, out_channels, 1, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = [block(x) for block in self.aspp_blocks]\n",
        "        global_features = self.global_avg_pool(x)\n",
        "        global_features = nn.Upsample(size=x.size()[2:], mode='bilinear', align_corners=True)(global_features)\n",
        "        features.append(global_features)\n",
        "        return torch.cat(features, dim=1)\n",
        "\n",
        "\n",
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, channel, reduction=16):\n",
        "        super(SEBlock, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y.expand_as(x)\n",
        "\n",
        "\n",
        "class PSPModule(nn.Module):\n",
        "    def __init__(self, in_channels, bin_sizes):\n",
        "        super(PSPModule, self).__init__()\n",
        "        self.stages = nn.ModuleList([self._make_stage(in_channels, size) for size in bin_sizes])\n",
        "        self.bottleneck = nn.Conv2d(in_channels * (len(bin_sizes) + 1), in_channels, kernel_size=1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def _make_stage(self, in_channels, size):\n",
        "        prior = nn.AdaptiveAvgPool2d(output_size=(size, size))\n",
        "        conv = nn.Conv2d(in_channels, in_channels, kernel_size=1, bias=False)\n",
        "        return nn.Sequential(prior, conv)\n",
        "\n",
        "    def forward(self, feats):\n",
        "        h, w = feats.size(2), feats.size(3)\n",
        "        pyramids = [feats]\n",
        "        pyramids.extend([nn.functional.interpolate(stage(feats), size=(h, w), mode='bilinear', align_corners=True) for stage in self.stages])\n",
        "        output = torch.cat(pyramids, dim=1)\n",
        "        return self.relu(self.bottleneck(output))\n",
        "\n",
        "\n",
        "class PSPDeep(pl.LightningModule):\n",
        "    def __init__(self, in_channels=13, num_classes=3):\n",
        "        super(PSPDeep, self).__init__()\n",
        "\n",
        "        self.weight = torch.Tensor([1.93445299, 36.60054169, 2.19400729])\n",
        "\n",
        "        self.resnet101 = models.resnet101(pretrained=True)\n",
        "        self.resnet101.conv1 = nn.Conv2d(in_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "        # 编码器部分\n",
        "        self.enc1 = nn.Sequential(self.resnet101.conv1, self.resnet101.bn1, self.resnet101.relu, self.resnet101.maxpool)\n",
        "        self.enc2 = self.resnet101.layer1\n",
        "\n",
        "        self.enc3 = self.resnet101.layer2\n",
        "\n",
        "        self.enc4 = self.resnet101.layer3\n",
        "\n",
        "        self.enc5 = self.resnet101.layer4\n",
        "\n",
        "        self.aspp1 = ASPP(2048, 256)\n",
        "        self.project1 = nn.Sequential(nn.Conv2d(1280, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
        "                      nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Dropout(p=0.5, inplace=False))\n",
        "\n",
        "        self.psp = PSPModule(2048, [1, 4, 9, 16, 25])\n",
        "        self.project2 = nn.Sequential(nn.Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
        "                      nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Dropout(p=0.5, inplace=False))\n",
        "        self.up1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        # self.up2 = nn.Upsample(scale_factor=4, mode='bilinear', align_corners=True)\n",
        "        self.dec5 = self.conv_block(2048, 1024)\n",
        "        self.dec4 = self.conv_block(1024, 512)\n",
        "        self.dec3 = self.conv_block(512, 256)\n",
        "        self.dec2 = self.conv_block(256, 64)\n",
        "        # self.dec1 = nn.Conv2d(64, num_classes, 1)\n",
        "        self.classfication = nn.Conv2d(64, num_classes, kernel_size=(1, 1), stride=(1, 1))\n",
        "\n",
        "\n",
        "    def conv_block(self, in_channels, out_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        enc1 = self.enc1(x)\n",
        "        enc2 = self.enc2(enc1)\n",
        "        enc3 = self.enc3(enc2)\n",
        "        enc4 = self.enc4(enc3)\n",
        "        enc5 = self.enc5(enc4)\n",
        "\n",
        "        aspp1 = self.aspp1(enc5)\n",
        "        project1 = self.project1(aspp1)\n",
        "\n",
        "        psp = self.psp(enc5)\n",
        "        project2 = self.project2(psp)\n",
        "\n",
        "        dec5 = self.dec5(self.up1(torch.cat((project1,project2), dim=1)))\n",
        "        dec4 = self.dec4(self.up1(dec5))\n",
        "        dec3 = self.dec3(self.up1(dec4))\n",
        "        dec2 = self.dec2(self.up1(dec3))\n",
        "\n",
        "        classification = self.classfication(self.up1(dec2))\n",
        "\n",
        "        return classification\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch[\"image\"].cuda(), batch[\"mask\"].squeeze(1).cuda()\n",
        "        y_hat = self(x)\n",
        "        loss = self.cross_entropy_loss_mask_invalid(y_hat, y, weight=self.weight)\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "\n",
        "        x, y = batch[\"image\"].cuda(), batch[\"mask\"].squeeze(1).cuda()\n",
        "        y_hat = self(x)\n",
        "\n",
        "        loss = self.cross_entropy_loss_mask_invalid(y_hat, y, weight=self.weight)\n",
        "\n",
        "        self.log('val_loss', loss)\n",
        "\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
        "\n",
        "    def cross_entropy_loss_mask_invalid(self, logits: torch.Tensor, target:torch.Tensor, weight=None) -> float:\n",
        "\n",
        "      assert logits.dim() == 4, \"Expected logits to have 4 dimensions, but got {} dimensions.\".format(logits.dim())\n",
        "      assert target.dim() == 3, \"Expected target to have 3 dimensions, but got {} dimensions.\".format(target.dim())\n",
        "\n",
        "      valid = (target != 0)\n",
        "      target_without_invalids = (target - 1) * valid\n",
        "\n",
        "      weight = weight.cuda()\n",
        "      logits = logits.cuda()\n",
        "      target_without_invalids = target_without_invalids.cuda()\n",
        "    # BCE Loss (ignoring invalid values)\n",
        "      criterion = nn.CrossEntropyLoss(weight=weight.cuda(), reduction='none')  # (B, 1, H, W)\n",
        "\n",
        "      bce = criterion(logits, target_without_invalids)\n",
        "\n",
        "      bce *= valid  # mask out invalid pixels\n",
        "\n",
        "      return torch.sum(bce / (torch.sum(valid) + 1e-6))\n",
        "\n"
      ],
      "metadata": {
        "id": "NwMjePwGWC5A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}